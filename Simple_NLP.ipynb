{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โหลดดิคส่วนตัวครับ (ผมนิยมสร้างดิคเองเพื่อวิเคราะห์เรื่องที่สนใจ เช่น อยากวิเคราะห์ลิปติค ผมก็จะมีเฉพาะคำพื้นฐานกับคำที่เกี่ยวกับลิปสติค) <br> กับความถี่ในแต่ละคำที่เจอจาก Thai Corpus โดย Nectec ครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line.rstrip('\\n') for line in open('mydict.csv',encoding='utf8')]\n",
    "freq = [line.rstrip('\\n').split(\"\\t\") for line in open('ttc_freq.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ผมทำการเก็บข้อมูลคำแต่ละคำกับความยาวของคำและความถี่ที่เกิดขึ้นไว้ด้วยกันครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqlist = []\n",
    "lenlist = []\n",
    "for i in range(0,len(lines)):\n",
    "    freqlist.append(0)\n",
    "    lenlist.append(len(lines[i]))\n",
    "    for j in range(0,len(freq)):\n",
    "        if (lines[i] == freq[j][0]):\n",
    "            freqlist[i] = (int(freq[j][1]))\n",
    "            break    \n",
    "alllist = list(zip(lines,lenlist,freqlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทำการเพิ่มคำพิเศษบางอย่างที่สนใจเข้าไปในพจนานุกรม และเรียงคำตามความยาวและความถี่ที่เกิดครับ เพื่อเก็บเป็นดิคสำหรับตัดคำ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alllist.append(['หมดพาสชั่น'])\n",
    "alllist_sort = np.array(sorted(alllist, key = lambda x: (x[1], x[2]), reverse=True))\n",
    "wordlist = alllist_sort[:,0]\n",
    "wordlist = lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้างฟังก์ชั่นที่ใคัดเฉพาะภาษาไทยออกมาครับ ใช้ในบางกรณีที่ผมสนใจวิเคราะห์เฉพาะภาษาไทยเท่านั้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isThai(chr):\n",
    "    cVal = ord(chr)\n",
    "    if(cVal >= 3584 and cVal <= 3711):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้างฟังค์ชั่นตัดคำง่ายๆโดย อิงตามดิคขึ้นมาครับ เพราะผมมีปัญหากับการใช้ PyThaiNLP ในบางลักษณะพิเศษครับ จริงๆแล้วของ PyThaiNLP ทำงานเร็วกว่าฟังก์ชั่นนี้มากครับ <br>\n",
    "ผมทำความสะอาดในงานนี้แค่เอาเฉพาะภาษาไทย และตัดช่องว่างทั้งหมดออก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string, length):\n",
    "    # Only Thai Filter\n",
    "    string = ''.join(list(filter(isThai, string)))\n",
    "    # Remove Space\n",
    "    string = string.replace(' ','')\n",
    "    result = dict() \n",
    "    for word in wordlist:\n",
    "        if len(word) > length:\n",
    "            s = 0\n",
    "            while (1):\n",
    "                s = string.find(word, s)\n",
    "                if (s == -1):\n",
    "                    break\n",
    "                else:\n",
    "                    s = s + 1\n",
    "                    result[s] = word\n",
    "            string = string.replace(word,'X'*len(word))  \n",
    "    return [value for (key, value) in sorted(result.items())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โหลดข้อความแล้วก็ทำการตัดคำครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [line.rstrip('\\n') for line in open('mydata.csv',encoding='utf8')]\n",
    "\n",
    "# Tokenization\n",
    "comments_clean = [];\n",
    "for sentence in comments:\n",
    "    comments_clean.append(' '.join(tokenize(sentence,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
